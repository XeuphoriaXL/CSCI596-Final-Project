{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, Select GPU in the runtime session."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change environment:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTK-qbKMUBmE"
   },
   "outputs": [],
   "source": "!sed -i 's/np.complex/np.complex128/g' /usr/local/lib/python3.10/dist-packages/librosa/core/constantq.py"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "import necessary requirements:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%pip install --upgrade pip\n",
    "%pip uninstall -y tensorflow numba\n",
    "%pip install matplotlib\\\n",
    "numpy==1.19.3 \\\n",
    "inflect==0.2.5 \\\n",
    "librosa==0.6.0 \\\n",
    "Unidecode==1.0.22 \\\n",
    "pillow\n",
    "%pip install janome==0.4.2\n",
    "%pip install denoiser==0.1.0\n",
    "%pip install librosa==0.8.0\n",
    "%pip install numba\n",
    "%pip install pysoundfile==0.9.0.post1\n",
    "%pip install unidecode==1.3.4\n",
    "%pip install pyopenjtalk==0.2.0\n",
    "%pip install inflect==5.6.2\n",
    "%pip install janome==0.4.2"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clone repo from github:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!git clone https://github.com/XeuphoriaXL/CSCI596-Final-Project.git\n",
    "!cp -r /content/CSCI596-Final-Project/* /content"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Download pre-trained model:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!gdown --folder \"https://drive.google.com/drive/folders/1ql2jv4JTL7klWXQTMSnJmrMNMc1aRU5Q?usp=drive_link\" -O /content\n",
    "#!cp -r /content/tacotron2-japanese/* /content"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install pyopenjtalk\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import IPython.display as ipd\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import tracemalloc\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import librosa             # MODIFICATION\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After the error, run the below cell and then run the upper cell again."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!sed -i 's/np.complex/np.complex128/g' /usr/local/lib/python3.10/dist-packages/librosa/core/constantq.py"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from waveglow.denoiser import Denoiser"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    \"\"\"\n",
    "    plot function to measure vectorized data distribution\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='lower',\n",
    "                       interpolation='none')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def measure_time_and_memory(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Utility function to measure time and memory usage for a function.\n",
    "    \"\"\"\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    print(f\"Execution time: {end_time - start_time:.2f}s\")\n",
    "    print(f\"Current memory usage: {current / 10 ** 6:.2f}MB; Peak: {peak / 10 ** 6:.2f}MB\")\n",
    "    return result"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#ayachi_nene_1, ayachi_nene_3, and other modules under content also available\n",
    "checkpoint_path = \"ayachi_nene_2\"\n",
    "model = load_model(hparams)\n",
    "#load voice model into Cuda memory\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "_ = model.cuda().eval()#.half()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "waveglow_path = 'waveglow_256channels_universal_v5.pt'\n",
    "waveglow = torch.load(waveglow_path)['model']\n",
    "#load waveglow model into Cuda memory\n",
    "waveglow.cuda().eval()#.half()\n",
    "for k in waveglow.convinv:\n",
    "    k.float()\n",
    "denoiser = Denoiser(waveglow)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#replace text with anything you want in hiragana or katakana; examples in readme\n",
    "text = \"こんにちは。あやちねねです。どうぞよろしくお願いいたします。\"\n",
    "sequence = np.array(text_to_sequence(text, ['japanese_cleaners']))[None, :]\n",
    "#load sequence in Cuda\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).cuda().long()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Measure performance of model inference\n",
    "mel_outputs, mel_outputs_postnet, _, alignments = measure_time_and_memory(\n",
    "    model.inference, sequence\n",
    ")\n",
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Measure performance of WaveGlow audio generation\n",
    "with torch.no_grad():\n",
    "    audio = measure_time_and_memory(waveglow.infer, mel_outputs_postnet, sigma=0.666)\n",
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#plot waveglow \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "audio_data = audio[0].data.cpu().numpy()\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(audio_data)\n",
    "plt.title(\"Generated Audio Waveform\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()  # Make sure this is included"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run this cell if you wish to download the audio"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import soundfile as sf\n",
    "from google.colab import files\n",
    "\n",
    "# Extract the audio data as a NumPy array\n",
    "audio_np = audio[0].data.cpu().numpy()\n",
    "\n",
    "# Write it to a WAV file (16-bit PCM)\n",
    "sf.write('generated_audio.wav', audio_np, hparams.sampling_rate, subtype='PCM_16')\n",
    "\n",
    "# Download the file\n",
    "files.download('generated_audio.wav')"
   ]
  }
 ]
}
